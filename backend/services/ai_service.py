import os
import json
import google.generativeai as genai
from dotenv import load_dotenv
from google.generativeai.types import GenerationConfig

from tenacity import retry, stop_after_attempt, wait_fixed, retry_if_exception_type
from google.api_core import exceptions as google_exceptions


load_dotenv()
api_key = os.getenv("GEMINI_API_KEY")

if not api_key:
    raise ValueError("L·ªói: Kh√¥ng t√¨m th·∫•y API Key trong file .env")

genai.configure(api_key=api_key)

# S·ª≠ d·ª•ng Model 1.5 Flash (Nhanh & ·ªîn ƒë·ªãnh)
model = genai.GenerativeModel('gemini-2.5-flash')

# C·∫•u h√¨nh JSON Mode
json_config = GenerationConfig(
    response_mime_type="application/json"
)

# N·∫øu g·∫∑p l·ªói server ho·∫∑c qu√° t·∫£i, code s·∫Ω:
# - Th·ª≠ l·∫°i t·ªëi ƒëa 3 l·∫ßn
# - M·ªói l·∫ßn ch·ªù 2 gi√¢y
retry_strategy = retry(
    stop=stop_after_attempt(3),
    wait=wait_fixed(2),
    retry=retry_if_exception_type((
        google_exceptions.ResourceExhausted, # L·ªói 429 (Qu√° nhanh)
        google_exceptions.ServiceUnavailable, # L·ªói 503 (Server b·∫≠n)
        google_exceptions.DeadlineExceeded,   # L·ªói Timeout
    ))
)


# L√ïI AI S·ªê 1: CHU·∫®N H√ìA & S·ª¨A L·ªñI CH√çNH T·∫¢ 
@retry_strategy
def clean_and_correct_list(raw_input_string: str) -> list[str]:
    """
    L√µi 1: Nh·∫≠n danh s√°ch th√¥ -> Tr·∫£ v·ªÅ danh s√°ch s·∫°ch.
    """
    
    # Prompt chu·∫©n t·ª´ User
    prompt = f"""
    ROLE: You are a strict English Spell Checker and Formatter.
    
    INPUT: A raw list of English vocabulary words or phrasal verb (separated by newlines or commas), possibly containing typos.
    
    TASK:
    1. Read each line/item.
    2. **Spell Check**: Correct any spelling mistakes (e.g., "integrat" -> "integrate").
    3. **Preserve Form**: Keep the word form exactly as intended (e.g., if input is "utilization", keep "utilization", DO NOT change to "utilize").
    4. **Ignore**: Remove empty lines or non-word characters.
    
    OUTPUT FORMAT: Return strictly a JSON Array of strings.
    
    FEW-SHOT EXAMPLES:
    - Input: 
      native to 
      utilization
      diverse
    - Output: ["native to", "utilization", "diverse"]
    
    - Input: stay clear of, anaylsis
    - Output: ["stay clear of", "analysis"]

    ACTUAL INPUT TO PROCESS:
    ---
    {raw_input_string}
    ---
    """
    
    print("--- üßπ [L√µi 1] ƒêang x·ª≠ l√Ω (C√≥ Retry)... ---")
    try:
        response = model.generate_content(prompt, generation_config=json_config)
        return json.loads(response.text)
    except Exception as e:
        print(f"L·ªói L√µi 1 (ƒê√£ h·∫øt l∆∞·ª£t th·ª≠): {e}")
        return []

# L√ïI AI S·ªê 2: L√ÄM GI√ÄU D·ªÆ LI·ªÜU
@retry_strategy
def enrich_word_batch(word_list: list[str]) -> list[dict]:
    """
    L√µi 2: Nh·∫≠n list t·ª´ s·∫°ch -> Tr·∫£ v·ªÅ th√¥ng tin chi ti·∫øt Flashcard.
    """
    
    input_data = json.dumps(word_list)
    
    # Prompt chu·∫©n t·ª´ User
    prompt = f"""
    ROLE: You are an expert Dictionary Generator.
    TASK: Generate detailed flashcard data for this list of words: {input_data}
    
    OUTPUT REQUIREMENTS:
    Return a JSON Array where each object follows this EXACT schema:
    {{
      "word": "The original word",
      "ipa": "IPA transcription (e.g., /h…ôÀàl…ô ä/)",
      "type": "Part of speech (n, v, adj...)",
      "vietnamese": "Meaning in Vietnamese (short & accurate)",
      "word_family": {{
          "noun": "Noun form (or null if none)",
          "verb": "Verb form (or null if none)",
          "adjective": "Adjective form (or null if none)",
          "adverb": "Adverb form (or null if none)"
      }},
      "synonyms": ["synonym 1", "synonym 2"],
      "collocations": ["collocation 1", "collocation 2 (2-3 items)"],
      "example_sentence": "A natural example sentence."
    }}
    """
    
    print(f"[L√µi 2] ƒêang g·ªçi AI cho {len(word_list)} t·ª´ (C√≥ Retry)...")
    try:
        response = model.generate_content(prompt, generation_config=json_config)
        return json.loads(response.text)
    except Exception as e:
        print(f"L·ªói L√µi 2 (ƒê√£ h·∫øt l∆∞·ª£t th·ª≠): {e}")
        return []

#L√ïI AI S·ªê 3: PH·∫¢N H·ªíI & CH·∫§M ƒêI·ªÇM
@retry_strategy
def check_user_sentence_stream(word: str, sentence: str):
    """
    Phi√™n b·∫£n Nh·∫≠n x√©t (Kh√¥ng ch·∫•m ƒëi·ªÉm):
    Tr·∫£ v·ªÅ: JSON (ƒê√∫ng/Sai + C√¢u s·ª≠a) + '|||' + L·ªùi nh·∫≠n x√©t chi ti·∫øt
    """
    prompt = f"""
    ROLE: You are a helpful and knowledgeable English Language Assistant for Vietnamese learners.
    
    TASK: Analyze the student's sentence regarding the usage of the word "{word}".
    
    GUIDELINES:
    1. **Be Constructive**: Focus on explaining grammar, vocabulary choice, or naturalness.
    2. **No Grading**: Do NOT provide a rating like "Good", "Bad", or "Excellent". Just feedback.
    3. **Correction**: If the sentence is unnatural or wrong, provide a better version.
    
    INPUT:
    - Word: "{word}"
    - User's Sentence: "{sentence}"
    
    OUTPUT FORMAT INSTRUCTIONS:
    1. First, output a VALID JSON object (no markdown) for technical assessment:
       {{"is_correct": boolean, "corrected_sentence": "..."}}
    2. Immediately follow with this exact separator: |||
    3. Finally, write the feedback/explanation in Vietnamese (Stream this part).

    EXAMPLE OUTPUT:
    {{ "is_correct": false, "corrected_sentence": "I go to school." }}|||C√¢u n√†y c·ªßa b·∫°n thi·∫øu gi·ªõi t·ª´ 'to'. ƒê·ªông t·ª´ 'go' khi ch·ªâ h∆∞·ªõng ƒëi c·∫ßn ƒëi k√®m v·ªõi 'to'...
    """
    
    print(f"----[L√µi 3] ƒêang Streaming (Ch·∫ø ƒë·ªô Nh·∫≠n x√©t)... ---")
    try:
        # Kh√¥ng d√πng json_config ƒë·ªÉ cho ph√©p tr·∫£ v·ªÅ h·ªón h·ª£p
        response = model.generate_content(prompt, stream=True)
        
        for chunk in response:
            if chunk.text:
                yield chunk.text
            
    except Exception as e:
        print(f"L·ªói Stream: {e}")
        yield json.dumps({"error": "L·ªói h·ªá th·ªëng AI"})